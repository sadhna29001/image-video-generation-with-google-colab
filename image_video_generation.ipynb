{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6864b03f",
   "metadata": {},
   "source": [
    "# Image & Video Generation with Gradio\n",
    "\n",
    "This notebook provides a complete interface for generating images and videos using AI models.\n",
    "\n",
    "**Features:**\n",
    "- Text-to-Image generation using Stable Diffusion\n",
    "- Text-to-Video generation\n",
    "- Interactive Gradio interface\n",
    "\n",
    "**Note:** This notebook is optimized for Google Colab with GPU support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5fb538",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d46d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q diffusers transformers accelerate torch torchvision gradio xformers safetensors\n",
    "!pip install -q opencv-python imageio imageio-ffmpeg\n",
    "print(\"‚úÖ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f80fe7",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5cf45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gradio as gr\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from diffusers import DiffusionPipeline\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94a6d79",
   "metadata": {},
   "source": [
    "## 3. Setup Image Generation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4607ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Stable Diffusion model for image generation\n",
    "print(\"Loading Stable Diffusion model...\")\n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize the pipeline\n",
    "image_pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    safety_checker=None\n",
    ")\n",
    "\n",
    "# Use DPM-Solver for faster generation\n",
    "image_pipe.scheduler = DPMSolverMultistepScheduler.from_config(image_pipe.scheduler.config)\n",
    "image_pipe = image_pipe.to(device)\n",
    "\n",
    "# Enable memory optimizations\n",
    "if torch.cuda.is_available():\n",
    "    image_pipe.enable_attention_slicing()\n",
    "    try:\n",
    "        image_pipe.enable_xformers_memory_efficient_attention()\n",
    "        print(\"‚úÖ XFormers enabled for better performance\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è XFormers not available, using standard attention\")\n",
    "\n",
    "print(\"‚úÖ Image generation model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972bc297",
   "metadata": {},
   "source": [
    "## 4. Setup Video Generation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dad2088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text-to-video model\n",
    "print(\"Loading video generation model...\")\n",
    "\n",
    "try:\n",
    "    # Using ModelScope text-to-video model\n",
    "    !pip install -q modelscope\n",
    "    from modelscope.pipelines import pipeline\n",
    "    from modelscope.outputs import OutputKeys\n",
    "    \n",
    "    video_pipe = pipeline('text-to-video-synthesis', 'damo/text-to-video-ms-1.7b')\n",
    "    video_model_loaded = True\n",
    "    print(\"‚úÖ Video generation model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not load video model: {e}\")\n",
    "    print(\"Video generation will use image-to-video alternative\")\n",
    "    video_model_loaded = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc599e5",
   "metadata": {},
   "source": [
    "## 5. Define Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b47a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(prompt, negative_prompt=\"\", num_steps=25, guidance_scale=7.5, seed=-1):\n",
    "    \"\"\"\n",
    "    Generate an image from a text prompt.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Text description of the desired image\n",
    "        negative_prompt: What to avoid in the image\n",
    "        num_steps: Number of denoising steps (higher = better quality, slower)\n",
    "        guidance_scale: How closely to follow the prompt (7-12 recommended)\n",
    "        seed: Random seed for reproducibility (-1 for random)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set seed for reproducibility\n",
    "        generator = None\n",
    "        if seed != -1:\n",
    "            generator = torch.Generator(device=device).manual_seed(seed)\n",
    "        \n",
    "        # Generate image\n",
    "        with torch.autocast(device):\n",
    "            result = image_pipe(\n",
    "                prompt=prompt,\n",
    "                negative_prompt=negative_prompt,\n",
    "                num_inference_steps=num_steps,\n",
    "                guidance_scale=guidance_scale,\n",
    "                generator=generator\n",
    "            )\n",
    "        \n",
    "        return result.images[0]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating image: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_video(prompt, num_frames=16, fps=8):\n",
    "    \"\"\"\n",
    "    Generate a video from a text prompt.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Text description of the desired video\n",
    "        num_frames: Number of frames to generate\n",
    "        fps: Frames per second for the output video\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if video_model_loaded:\n",
    "            # Use ModelScope text-to-video\n",
    "            output = video_pipe(prompt)\n",
    "            video_path = output[OutputKeys.OUTPUT_VIDEO]\n",
    "            return video_path\n",
    "        else:\n",
    "            # Fallback: Create video from interpolated images\n",
    "            print(\"Using image-based video generation...\")\n",
    "            \n",
    "            frames = []\n",
    "            for i in range(num_frames):\n",
    "                # Generate image with slight variation\n",
    "                seed = i * 1000\n",
    "                img = generate_image(\n",
    "                    prompt=f\"{prompt}, frame {i}\",\n",
    "                    num_steps=20,\n",
    "                    seed=seed\n",
    "                )\n",
    "                if img:\n",
    "                    frames.append(np.array(img))\n",
    "            \n",
    "            if frames:\n",
    "                # Save as video\n",
    "                output_path = \"generated_video.mp4\"\n",
    "                imageio.mimsave(output_path, frames, fps=fps)\n",
    "                return output_path\n",
    "            else:\n",
    "                return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating video: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_interpolation_video(start_prompt, end_prompt, num_frames=30, fps=10):\n",
    "    \"\"\"\n",
    "    Create a video that interpolates between two prompts.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        frames = []\n",
    "        \n",
    "        # Generate start and end images\n",
    "        start_img = generate_image(start_prompt, num_steps=30)\n",
    "        end_img = generate_image(end_prompt, num_steps=30)\n",
    "        \n",
    "        if start_img and end_img:\n",
    "            start_array = np.array(start_img)\n",
    "            end_array = np.array(end_img)\n",
    "            \n",
    "            # Linear interpolation\n",
    "            for i in range(num_frames):\n",
    "                alpha = i / (num_frames - 1)\n",
    "                frame = ((1 - alpha) * start_array + alpha * end_array).astype(np.uint8)\n",
    "                frames.append(frame)\n",
    "            \n",
    "            # Save video\n",
    "            output_path = \"interpolation_video.mp4\"\n",
    "            imageio.mimsave(output_path, frames, fps=fps)\n",
    "            return output_path\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating interpolation: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Generation functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4fda85",
   "metadata": {},
   "source": [
    "## 6. Create Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72623e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gradio interface with tabs for different functionalities\n",
    "\n",
    "with gr.Blocks(title=\"AI Image & Video Generator\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üé® AI Image & Video Generator\n",
    "    Generate stunning images and videos using state-of-the-art AI models!\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Tabs():\n",
    "        # Tab 1: Image Generation\n",
    "        with gr.Tab(\"üñºÔ∏è Image Generation\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    img_prompt = gr.Textbox(\n",
    "                        label=\"Prompt\",\n",
    "                        placeholder=\"Describe the image you want to generate...\",\n",
    "                        lines=3\n",
    "                    )\n",
    "                    img_negative = gr.Textbox(\n",
    "                        label=\"Negative Prompt (Optional)\",\n",
    "                        placeholder=\"What to avoid in the image...\",\n",
    "                        lines=2\n",
    "                    )\n",
    "                    \n",
    "                    with gr.Row():\n",
    "                        img_steps = gr.Slider(\n",
    "                            minimum=10,\n",
    "                            maximum=50,\n",
    "                            value=25,\n",
    "                            step=1,\n",
    "                            label=\"Steps\"\n",
    "                        )\n",
    "                        img_guidance = gr.Slider(\n",
    "                            minimum=1,\n",
    "                            maximum=20,\n",
    "                            value=7.5,\n",
    "                            step=0.5,\n",
    "                            label=\"Guidance Scale\"\n",
    "                        )\n",
    "                    \n",
    "                    img_seed = gr.Number(\n",
    "                        label=\"Seed (-1 for random)\",\n",
    "                        value=-1\n",
    "                    )\n",
    "                    \n",
    "                    img_button = gr.Button(\"Generate Image\", variant=\"primary\")\n",
    "                \n",
    "                with gr.Column():\n",
    "                    img_output = gr.Image(label=\"Generated Image\", type=\"pil\")\n",
    "            \n",
    "            img_button.click(\n",
    "                fn=generate_image,\n",
    "                inputs=[img_prompt, img_negative, img_steps, img_guidance, img_seed],\n",
    "                outputs=img_output\n",
    "            )\n",
    "            \n",
    "            gr.Examples(\n",
    "                examples=[\n",
    "                    [\"A serene mountain landscape at sunset, photorealistic\", \"blurry, low quality\"],\n",
    "                    [\"A futuristic cyberpunk city with neon lights, 4k\", \"ugly, distorted\"],\n",
    "                    [\"A cute cat wearing a wizard hat, studio lighting\", \"\"]\n",
    "                ],\n",
    "                inputs=[img_prompt, img_negative]\n",
    "            )\n",
    "        \n",
    "        # Tab 2: Video Generation\n",
    "        with gr.Tab(\"üé¨ Video Generation\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    vid_prompt = gr.Textbox(\n",
    "                        label=\"Prompt\",\n",
    "                        placeholder=\"Describe the video you want to generate...\",\n",
    "                        lines=3\n",
    "                    )\n",
    "                    \n",
    "                    with gr.Row():\n",
    "                        vid_frames = gr.Slider(\n",
    "                            minimum=8,\n",
    "                            maximum=32,\n",
    "                            value=16,\n",
    "                            step=1,\n",
    "                            label=\"Number of Frames\"\n",
    "                        )\n",
    "                        vid_fps = gr.Slider(\n",
    "                            minimum=4,\n",
    "                            maximum=24,\n",
    "                            value=8,\n",
    "                            step=1,\n",
    "                            label=\"FPS\"\n",
    "                        )\n",
    "                    \n",
    "                    vid_button = gr.Button(\"Generate Video\", variant=\"primary\")\n",
    "                \n",
    "                with gr.Column():\n",
    "                    vid_output = gr.Video(label=\"Generated Video\")\n",
    "            \n",
    "            vid_button.click(\n",
    "                fn=generate_video,\n",
    "                inputs=[vid_prompt, vid_frames, vid_fps],\n",
    "                outputs=vid_output\n",
    "            )\n",
    "            \n",
    "            gr.Examples(\n",
    "                examples=[\n",
    "                    [\"A astronaut floating in space\"],\n",
    "                    [\"Ocean waves crashing on a beach\"]\n",
    "                ],\n",
    "                inputs=[vid_prompt]\n",
    "            )\n",
    "        \n",
    "        # Tab 3: Interpolation Video\n",
    "        with gr.Tab(\"üîÑ Prompt Interpolation\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    interp_start = gr.Textbox(\n",
    "                        label=\"Start Prompt\",\n",
    "                        placeholder=\"Starting scene...\",\n",
    "                        lines=2\n",
    "                    )\n",
    "                    interp_end = gr.Textbox(\n",
    "                        label=\"End Prompt\",\n",
    "                        placeholder=\"Ending scene...\",\n",
    "                        lines=2\n",
    "                    )\n",
    "                    \n",
    "                    with gr.Row():\n",
    "                        interp_frames = gr.Slider(\n",
    "                            minimum=10,\n",
    "                            maximum=60,\n",
    "                            value=30,\n",
    "                            step=1,\n",
    "                            label=\"Number of Frames\"\n",
    "                        )\n",
    "                        interp_fps = gr.Slider(\n",
    "                            minimum=5,\n",
    "                            maximum=30,\n",
    "                            value=10,\n",
    "                            step=1,\n",
    "                            label=\"FPS\"\n",
    "                        )\n",
    "                    \n",
    "                    interp_button = gr.Button(\"Create Interpolation\", variant=\"primary\")\n",
    "                \n",
    "                with gr.Column():\n",
    "                    interp_output = gr.Video(label=\"Interpolation Video\")\n",
    "            \n",
    "            interp_button.click(\n",
    "                fn=create_interpolation_video,\n",
    "                inputs=[interp_start, interp_end, interp_frames, interp_fps],\n",
    "                outputs=interp_output\n",
    "            )\n",
    "            \n",
    "            gr.Examples(\n",
    "                examples=[\n",
    "                    [\"A sunny day in the park\", \"A starry night sky\"],\n",
    "                    [\"A red rose\", \"A blue orchid\"]\n",
    "                ],\n",
    "                inputs=[interp_start, interp_end]\n",
    "            )\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "    ---\n",
    "    ### Tips:\n",
    "    - **Image Generation**: Use detailed descriptions for better results. Higher steps = better quality but slower.\n",
    "    - **Video Generation**: Keep prompts simple and descriptive. Video generation takes longer.\n",
    "    - **Interpolation**: Creates smooth transitions between two different scenes.\n",
    "    \"\"\")\n",
    "\n",
    "print(\"‚úÖ Gradio interface created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57850c69",
   "metadata": {},
   "source": [
    "## 7. Launch the Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19db7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the Gradio interface\n",
    "demo.launch(\n",
    "    share=True,  # Creates a public link\n",
    "    debug=True,\n",
    "    show_error=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7ebca5",
   "metadata": {},
   "source": [
    "## 8. Additional Configuration (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1658a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Test individual functions\n",
    "\n",
    "# Test image generation\n",
    "# test_img = generate_image(\"a beautiful sunset over mountains\")\n",
    "# display(test_img)\n",
    "\n",
    "# Test video generation\n",
    "# test_vid = generate_video(\"waves on a beach\", num_frames=8)\n",
    "# print(f\"Video saved to: {test_vid}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
